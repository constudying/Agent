# My First Project

> mimcplay通过视频教学获取当前图像对应任务的轨迹指引，这一模式使得模型很难迁移到未知任务中。
> 为了实现无目标图像时，能够仅根据当前图像获取未来动作的指引，增强其非熟悉环境的适应性，同时提供一种动作倾向，用于融入人机耦合动力学的引导，落脚于输出动作（序列）上。

vscode
vscode-copilot
github
deepseek
qq email

This repo is based on robosuite, bddl, LIBERO and robomimic.

1. v0.0.0: 建立初步模型，以及分阶段训练逻辑
2. v0.0.1: 修改模型，试验模糊量状态空间假设，尝试了一些初步修改（主要在highlevel模型上）：

- 20251101201547：修改了模型输入，原本只有图像模态输入的单链pipe，robot0_eef_pos并不输入
- 20251102003057：修改了模型输入，原本只有图像模态输入的单链pipe，robot0_eef_pos并不输入，并在decoder之前拼接transformer特征后输入其中
- 20251102010811：修改了模型输入，原本只有图像模态输入的单链pipe，robot0_eef_pos并不输入，并在decoder之前，在transformer和decoder之间加入了一个mlp，拼接transformer特征后输入其中，再接入decoder
- 20251102115409：相比于上一次学习，增加了特定epoch位置的学习率衰减，应对loss曲线均匀震荡的收敛问题。

> 上述训练问题在于缺少训练经验，对训练过程中的loss曲线趋势没有认识（修改前没有先复现一遍原模型），都只训练了200-300个epoch就结束，不知道模型复杂度与loss平滑性的经验规律如何。
> 同时也缺少对应复杂模型训练的解决技巧。

3. v0.0.2: 继续试验假设，另一方面空间转移向量的设置在原修改中没有凸显，需要详细设置。其可分为两方面，一方面是图像相对变化的特征建模，另一方面则是特征对应的动作获取策略。

关于图像状态转移向量的相应特征思考：相关残差网络论文说明残差连接是一种基于输入语义特征的小幅修正（深层残差网络的梯度集中在前部分的网络），f(x)在高层语义保持上因此直接

> 该方向暂时走不通，特征工程认识不充分，有待补充

4. v0.0.3: 通过interact论文发现cls能够实现交换不同模态信息的能力，可能有利于实现图像、深度与轨迹的对齐

问题：

- 对于transformer编解码器结构来说，轨迹样本太少，问题欠约束；
- cls作为一种上下文特征信息补充，没有在图像稀疏语义和深度几何连续方面的“硬性”分工能力
- 网络结构分工不明确
- 只有一个监督信号，缺少功能约束
