"""
为什么"历史轨迹 -> 未来轨迹"的任务仍然很困难？

你的输入特征
================================================================================

编码器输入 (encoder inputs):

- robot0_eef_pos: 当前末端执行器位置 [3]
- agentview_image: 相机图像 [C, H, W]
- agentview_depth: 深度图像 [C, H, W]

解码器输入 (decoder inputs):

- text: CLS token (任务embedding)
- robot0_eef_pos_past_traj: 过去10帧的位置轨迹 [10, 3]
- robot0_eef_pos_past_traj_delta: 过去9帧的位置增量 [9, 3]

预测目标:

- robot0_eef_pos_future_traj: 未来10帧的位置轨迹 [10, 3] -> 展平为 [30]

任务定义: 历史轨迹 + 当前观测 -> 未来轨迹
ac_dim = 30 (未来10帧 × 3维位置)

================================================================================
问题分析：为什么这个任务仍然很难？
================================================================================

1. **这不是行为克隆，是轨迹预测**

-------------------------------------------
行为克隆 (Behavior Cloning):

- 输入: 状态 s_t
- 输出: 动作 a_t
- 目标: 学习专家的决策策略 π(a|s)

轨迹预测 (Trajectory Prediction):

- 输入: 历史轨迹 [p_{t-10}, ..., p_t]
- 输出: 未来轨迹 [p_{t+1}, ..., p_{t+10}]
- 目标: 学习环境动力学 + 控制策略的复合效果

**关键区别**:

- BC学习的是"我应该怎么做" (what to do)
- 轨迹预测学的是"我会到哪里" (where I'll be)
  
你的模型在做后者，但BC需要的是前者！

2. **未来轨迹不是唯一确定的**

-------------------------------------------
即使历史轨迹完全相同，未来轨迹也可能不同，原因：

a) 专家的决策多样性

- 同样的历史，专家可能选择不同的动作
- 例如：绕左边还是绕右边抓物体
- 这是GMM应该建模的多模态性

b) 执行的不确定性

- 同样的动作，可能导致不同的轨迹
- 原因：物理仿真噪声、接触动力学、滑动等
- 这是环境的随机性，不是决策的多样性

c) 控制频率的影响

- 未来10帧 = 未来10个控制周期
- 如果控制频率是20Hz，这是0.5秒的未来
- 0.5秒后的位置依赖于0.5秒内的所有动作序列
- 你试图让模型一步预测10步后的结果！

3. **维度诅咒：30维输出空间太大**

-------------------------------------------
GMM拟合30维分布面临的挑战：

- 5个高斯模态，每个模态有30维均值和30维标准差
- 总共需要学习: 5 × (30 + 30) + 5 = 305个参数 (每个样本)
- 但30维空间中，数据是极其稀疏的
- GMM的协方差矩阵假设各维度独立（或对角阵），但时间步之间有强依赖

例如：

- future_traj[0:3] 是t+1时刻的xyz
- future_traj[3:6] 是t+2时刻的xyz
- 显然t+2依赖于t+1，不是独立的
- 但GMM的component_distribution = D.Independent(D.Normal, 1)
    假设了30个维度是独立的！

4. **历史无法预测未来（缺少关键信息）**

-------------------------------------------
你有历史轨迹，但缺少：

a) 当前的速度和加速度

- 虽然有past_traj_delta（位置增量），但这只是速度的粗略估计
- 没有加速度信息，无法外推运动趋势

b) 专家的意图

- 未来轨迹取决于专家想做什么
- 但意图不在历史轨迹中，在动作中
- 同样的历史轨迹，目标不同则未来轨迹完全不同

c) 环境的动力学模型

- 未来轨迹是动作通过环境动力学产生的
- 模型需要隐式学习：action + dynamics -> trajectory
- 但你没有给它看action！

举例说明：
  历史: [向右移动, 向右移动, 向右移动]
  图像: 物体在左边
  
  可能的未来1: [继续向右] (专家决定先移动到侧面)
  可能的未来2: [转向向左] (专家决定直接去抓)
  可能的未来3: [停止, 下降] (专家决定先下降)
  
  这三种未来对应不同的动作序列，但历史轨迹相同！
  模型怎么知道专家想做什么？

5. **为什么loss难以下降？**

-------------------------------------------

a) 任务本质上就很难

- 从历史预测未来需要理解因果关系
- 但训练数据只提供了相关性（轨迹序列）
- 模型在拟合一个under-determined问题

b) GMM的表达能力不足

- 5个高斯模态无法覆盖30维空间的所有可能未来
- 真实的未来分布可能是：
  - 沿着某些流形分布（如，未来轨迹必须满足运动学约束）
  - 有复杂的时间依赖（不是独立高斯）
  - 多模态的数量 >> 5

c) 优化困难

- log_prob(30维向量) 对细微的预测误差非常敏感
- 如果有一个时间步预测错了，整个30维向量的概率就会很低
- 梯度信号被稀释在30个维度上

d) 训练数据的多样性不足

- 即使有很多演示，30维空间中仍然极其稀疏
- GMM只能在训练样本附近拟合，泛化性差

================================================================================
为什么预测动作 (actions) 会更容易？
================================================================================

假设 batch["actions"] 是7维 (6个关节 + 1个夹爪)：

1. **维度大幅降低**
   - 7维 vs 30维
   - 参数量: 5×(7+7)+5 = 75 vs 5×(30+30)+5 = 305
   - 数据密度: 在7维空间中数据分布更密集

2. **直接建模决策**
   - action是专家的控制指令，直接反映意图
   - 不需要通过动力学模型推理

3. **单步预测 vs 多步预测**
   - 动作是当前时刻的决策，one-step
   - 轨迹是10步的累积效果，需要roll-out

4. **多模态更清晰**
   - 动作空间的多模态 = 专家的决策分支
   - 轨迹空间的多模态 = 决策分支 × 执行不确定性
   - 前者更容易用GMM建模

5. **物理约束更简单**
   - 动作空间: 关节速度限制（box constraints）
   - 轨迹空间: 运动学+动力学约束（流形constraints）

================================================================================
但是！你的任务也不是完全没有意义
================================================================================

如果你坚持预测轨迹，可能的原因：

1. **分层控制**
   - High-level: 预测期望的未来轨迹（目标）
   - Low-level: 根据目标轨迹生成动作（控制器）
   - 这是Model Predictive Control (MPC)的思路

2. **避免动作空间的歧义**
   - 如果动作是joint positions，同一个笛卡尔空间目标有多个逆解
   - 预测轨迹可以避免这个问题

3. **利用演示的空间信息**
   - 演示数据中，轨迹的形状包含了任务信息
   - 例如：绕圈、直线、Z字形等

================================================================================
解决方案
================================================================================

方案A: 改为预测动作（强烈推荐）
----------------------------------

修改 agent.py line 669:
  log_probs = dists.log_prob(batch["actions"])

优点:
  ✓ 标准的BC任务，有成熟的理论支撑
  ✓ 维度低，训练容易
  ✓ 多模态建模更准确

缺点:
  ✗ 需要确认actions维度是否等于ac_dim
  ✗ 如果ac_dim已经配置为30，需要改为action_dim

方案B: 只预测未来的终点（不是整条轨迹）
--------------------------------------------

修改目标为未来轨迹的最后一个点:
  target = batch["obs"]["robot0_eef_pos_future_traj"][:, -3:]  # 只要最后一个点的xyz

修改配置:
  ac_dim = 3

优点:
  ✓ 维度从30降到3，大幅简化
  ✓ GMM可以建模"去哪里"的多模态性
  ✓ 仍然是在任务空间预测

缺点:
  ✗ 丢失了轨迹的时序信息
  ✗ 需要low-level controller来执行

方案C: 使用序列模型预测轨迹（最复杂）
---------------------------------------

不要把30维展平，而是保持序列形式:

- 输出: [batch, 10, 3] (10个时间步，每步3维)
- 每个时间步一个GMM分布
- 使用autoregressive decoder: p(p_t+1 | p_t, a_t)

优点:
  ✓ 考虑了时间依赖
  ✓ 可以建模真实的序列生成过程

缺点:
  ✗ 需要大幅修改网络架构
  ✗ 训练更慢、更难
  ✗ 仍然缺少action信息

方案D: 同时预测动作和轨迹（混合方案）
---------------------------------------

输出两个head:

- Action head: [batch, action_dim] 用GMM
- Trajectory head: [batch, 30] 用确定性回归

损失函数:
  loss = -log_prob(actions) + λ * MSE(trajectory)

优点:
  ✓ 动作预测提供主要梯度
  ✓ 轨迹预测作为辅助任务，提供额外监督
  ✓ 可以分析两者的一致性

缺点:
  ✗ 增加了模型复杂度
  ✗ 需要调节λ

================================================================================
我的建议（分两步诊断）
================================================================================

第一步：先确认问题是否是维度不匹配
------------------------------------

在 _forward_training 中添加诊断代码:

```python
def _forward_training(self, batch):
    dists, entropy_loss = self.nets["policy"].forward_train(
        obs_dict=batch["obs"],
        goal_dict=batch["goal_obs"],
        return_attention_weights=True
    )
    
    assert len(dists.batch_shape) == 1
    
    # 添加诊断输出
    print("="*80)
    print("模型输出和目标维度诊断")
    print("="*80)
    print(f"GMM means shape: {dists.mean.shape}")  # 应该是 [batch, num_modes, ac_dim]
    print(f"Future traj shape: {batch['obs']['robot0_eef_pos_future_traj'].shape}")
    if 'actions' in batch:
        print(f"Actions shape: {batch['actions'].shape}")
    print(f"ac_dim from config: {self.ac_dim}")
    
    future_traj = batch["obs"]["robot0_eef_pos_future_traj"]
    log_probs_traj = dists.log_prob(future_traj)
    print(f"\nLog prob (future_traj):")
    print(f"  Mean: {log_probs_traj.mean().item():.4f}")
    print(f"  Min: {log_probs_traj.min().item():.4f}")
    print(f"  Max: {log_probs_traj.max().item():.4f}")
    
    if 'actions' in batch:
        log_probs_action = dists.log_prob(batch["actions"])
        print(f"\nLog prob (actions) - for comparison:")
        print(f"  Mean: {log_probs_action.mean().item():.4f}")
        print(f"  Min: {log_probs_action.min().item():.4f}")
        print(f"  Max: {log_probs_action.max().item():.4f}")
    
    print("="*80)
    
    log_probs = log_probs_traj
    # ... rest of the code
```

运行一个epoch，看输出。

第二步：根据结果决定修改方案
------------------------------

如果 log_prob < -100:
  → 模型完全没学到，可能是维度/目标选择问���
  → 建议改为方案A（预测动作）

如果 log_prob 在 -50 到 -10:
  → 模型在学习，但进展慢
  → 可能是任务确实很难
  → 尝试方案B（只预测终点）或继续调优

如果 actions 的log_prob明显高于 future_traj:
  → 说明预测动作确实更容易
  → 强烈建议改为方案A

================================================================================
总结
================================================================================

你的输入特征（历史轨迹、当前位置、图像）是合理的，但：

❌ 预测未来轨迹的任务本质上很难，因为：

- 未来不仅取决于历史，还取决于未来的动作（你没给）
- 30维空间中GMM难以拟合
- 时间依赖被忽略（GMM假设独立）

✅ 改为预测动作会更容易，因为：

- 维度更低（通常7维 vs 30维）
- 直接建模决策，不需要推理动力学
- 多模态更清晰（决策分支 vs 执行不确定性）

💡 核心问题不是Transformer的问题，是任务定义的问题：

- 你让模型做一个under-determined任务（历史→未来）
- 应该做determined任务（状态→动作）

建议：

1. 先加诊断代码，看看log_prob的数值
2. 对比actions和future_traj哪个更容易预测
3. 根据结果决定是否改为预测动作
"""

print(**doc**)
